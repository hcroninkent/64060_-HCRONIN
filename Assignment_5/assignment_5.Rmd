---
title: "assignment_5"
author: "Hannah Cronin"
date: "2022-11-29"
output: html_document
---
```{r}
library(readr)
Cereals <- read_csv("/Users/hannahcronin/Desktop/GITHUB/64060_-HCRONIN-FML/Assignment_5/Cereals.csv")
Cereal <- na.omit(Cereals)
head(Cereal)
library(cluster)
library(factoextra)
library(caret)
library(dplyr)
```
# To get rid of any rows with Nulls/NAs
```{r}
df = scale(Cereal[4:16]) #to normalize data
df = as.data.frame(df) #to make the data a data frame(so it can be partitioned later)
```
```{r}
d = dist(df, method = 'euclidean')
hc_single = agnes(df, method = 'single', metric = 'euclidean')
hc_complete = agnes(df, method = 'complete', metric = 'euclidean')
hc_average = agnes(df, method = 'average', metric = 'euclidean')
hc_ward = agnes(df, method = 'ward', metric = 'euclidean')
```
# The categorical variables are ommitted as they do not hold much value as this project focuses on nutritional value.
```{r}
print(hc_single$ac)
print(hc_complete$ac)
print(hc_average$ac)
print(hc_ward$ac)
```
# The Ward method is preferred as it provides the strongest clustering structure.

```{r}
tree = pltree(hc_ward, cex = .6, hang = -1, main = 'Dendogram of agnes')
```

```{r}
pltree(hc_ward, cex = 0.6)
rect.hclust(hc_ward, k = 5, border = 1:5)
```
```{r}
hc_ward_d <- hclust(d,method = "ward.D")
plot(hc_ward_d, cex = 0.6, hang=-1)
rect.hclust(hc_ward_d, k = 5, border = 1:5)
```

# The height I've chosen is about 20- which results in 5 clusters based on Euclidean distance.I tried to build this same graph using the Agnes function however the height was always 5 or sub-5 which I didn't not believe to be an accurate distance.


```{r}
cut = cutree(hc_ward, k = 5) 
cut #the composite of each cluster
clusters <- fviz_cluster(list(data = df, cluster = cut)) #visualization of the clusters
clusters
```
# To partition data to check stability
```{r}
mod = kmeans(df, centers = 5, nstart = 50)
mod$betweenss / mod$totss 
```
# About 52.5% of data stays within initial cluster
# Partitioning data
```{r}
Test = createDataPartition(df$calories, p = .5, list = FALSE)
part1 = df[Test,]
part2 = df[-Test,]
```
```{r}
clust_1<- agnes(part1, method="ward", metric = "euclidean")
clust_2 <- agnes(part2, method="ward", metric = "euclidean")
print(clust_1$ac) # 0.837
print(clust_2$ac) # 0.839
plot_1 <- pltree(clust_1, cex = 0.6, hang = -1)
plot_2 <- pltree(clust_2, cex = 0.6, hang = -1)
```
# The partitioned clusters look very similar and their agglomerative coefficients values are almost identical.

# To look at unscaled clusters for healthy cereals in schools
```{r}
c = kmeans(Cereal[4:12], centers = 5, nstart = 50)
Cereal = data.frame(Cereal, c$cluster)
c$center
```
Here we do not want to use standardized data, because the nutritional value is important to see on its own. For example, the ratio between carbohydrates and fiber (simple sugar vs complex/dietary sugars). Each factor becomes important to know rather than the scaled version. Based on these results, I'd recommend Cluster#2, because it has the fewest calories, a moderate amount of protein, a lower amount of fat, low sodium, higher fiber, moderate amount of carbs, low sugar, some potassium, and vitamins.


